---
title: "Logistic Regression on a basic dataset"
author: "sw"
format: html
editor: visual
execute:
 echo: false
embed-resources: true
---

**Introduction**

Logistic regression analysis is a type of regression model that is used when a dataset’s response variable is categorical in nature. When the response variable takes on two distinct outcome classes, a binary logistic regression model is used, and when there are more than two classes of the response variable, either a multinomial or ordinal logistic regression model can be deployed (cite text book). Logistic regression is commonly used across a variety of industries to glean insights about data and make better decisions; such fields include medicine, traffic and road engineering, environmental concerns, credit and fraud issues, and more. In this literature review, we take a closer look at logistic regression by discussing some applications of the logistic regression algorithm in various machine learning models, as well as several uses of logistic regression modeling in several peer- reviewed studies.

Many machine learning algorithms use logistic regression to train a model and make predictions about class labels. The article “…” investigates similarities between a logistic regression algorithm with gradient descent and a perceptron algorithm. Researchers observed that with very large steps, the logistic regression with gradient descent acts like a perceptron, which in some sense links it back to the Deep Equilibrium networks study. The conclusions from this paper are counter intuitive, and further research and reflections about classification and optimization theory are encouraged (citation).  

Another way LR is used in machine learning is through large language models (LLMs), which are complex neural networks trained on very large datasets to output human language (find source to cite). The paper “Large Language Model” addresses the problem of estimating the confidence of LLM outputs when only black-box (query-only) access is available. It is a simple technique that uses Logistic Regression to classify and validate the confidence of the outputs. Some problems of using black-box models are that there is no control over the model itself, and in some cases, the benefits and the value of buying these services that provide a black-box model outweigh training a personal, custom model. Therefore, this is a framework that attempts to overcome these challenges (Pedapati)

This article incorporates multinomial logistic regression in a machine learning model to classify text and improve natural language processing tasks (Shanbhag).

**LR in the medical field**

The article “Understanding Logistic Regression Analysis” discusses the usefulness of logistic regression, describes how to interpret results of the model, and gives an example of a logistic regression analysis using a synthetic dataset. The data is about patients undergoing a drug treatment with a categorical outcome variable that is binary in nature, taking on values of survived (1), or did not survive (0). The result of the analysis explains how to interpret output from the model; one must take the exponentials of the slopes in the model to find the chances (the probability) of an event occurring. It is noted that in order to correctly understand results of a logistic regression, one must carefully consider the differences between the odds ratio, the log odds, and the probabilities of events occurring. Another important point in the article states the importance of feature selection; a common way that predictors are selected for a logistic regression model is through a preliminary univariate analysis. During data preprocessing, all predictors are analyzed individually in relation to the outcome variable in a univariate analysis, and all significant predictors are used in the multivariate logistic regression analysis (cite source).

The article, “Determinants of coexistence of undernutrition and anemia among under- five children in Rwanda; evidence from 2019/20 demographic health survey: Application of bivariate binary logistic regression model” details a bivariate binary logistic regression model. There are two outcome variables: anemia and undernutrition in children under five years of age in Rwanda. The study analyzes the relationship between the two outcome variables, as well as the relationship between 26 predictors relating to the childrens’ preexisting health conditions, family information, details about the parents, and relevant geographic information. One result of the study was that the relationship between the two outcome variables, presence of malnutrition and presence of anemia, was found to be significant. It was also found that six predictors were found to be significant: mother’s age, drinking water, other children in household, child gender, birth order, and gender of head of household. The conclusion states that improving maternal education, supplementing with vitamin A and other nutrient dense foods, providing a healthy home environment environment, and decreasing maternal anemia may help improve rates of malnutrition and anemia in children.

In this study, “Predictors of hospital admission when presenting with acute on chronic breathlessness: Binary logistic regression” emergency room data from one hospital is analyzed to determine common predictors of patients that are admitted to the hospital. Specifically, patients presenting to the emergency room with acute on chronic breathlessness were surveyed to collect data that would help researchers understand common factors among those admitted to the hospital. Knowing common predictors ahead of time helps hospital staff more easily identify pateints who are more at risk for being admitted to the hospital, and also helps identify which patients would be more likely to be able to be discharged without being admitted. A binary logistic regression analysis of the data revealed that the odds of admission to the hospital were positively correlated with age, talking to a doctor about symptoms, and the presence of preexisting heart conditions; however, the odds of being admitted to the hospital were negatively associated with blood oxygen levels.

A new medical condition was recently recognized in 2004: airplane headache (AH), a condition described as a headache induced while while taking off or landing in an airplane. Because AH is a relatively new addition to medical dictionaries, it is an underexplored condition that requires additional research. This study saught to identify common risk factors significantly associated with airplane headache to aid both travelers and airline employees. Two binary logistic regression models were constructed to compare two groups against the airplane headache group. The first binary logistic regression compared the airplane headache group to the no headache group, and 10 significant predictors of AH were identified; this model’s predictive power was found to be very high. The second binary logistic regression model compared the airplane headache group to a group labelled “other headache” (individuals with symptoms of other types of headaches). The result from this analysis showed four significant predictors; however, the predictive power of the model was shown to be very low. To conclude, it can be stated that binary logistic regression is a very effective way to find strong predictors of airplane headache when compared to those who do not have any headaches while flying (Prottengeier).

One other useful way logistic regression is applied in the medical field is in identifying how the general public makes decisions regarding their health. Researchers in China analyzed 2696 health survey responses collected from individuals across 31 different Chinese provinces. They analyzed the data with a binary logistic regression model to classify points into two categories: unilateral decision making (value of 1), or collaborative decision making (value of 0); the researchers wanted to identify top predictors of individuals that make medical decisions by themselves and which predictors are correlated with patients making health decisions with more than one party (i.e. a patients, doctor, and family member all helping to make the health decision). It was found that most responses were classified as collaborative decision making (70%), which supports the idea that individuals in China strongly value family- made decisions and strong family values. It was also concluded that

significant predictors of unilateral decision making were gender, education level, family status, religious beliefs and occupation (Liu J. 2024).

Logistic Regression is also useful in detecting common diseases, such as breast cancer. “this study” uses regularized logistic regression along with biological network information and pairwise interactions, to find biomarkers, both single and interacting pairs, for breast cancer. Researchers prioritized biologically plausible biomarker combinations and used an adaptive elastic net, a penalty that balances l1 and l2, with network constraints. The result of the study shows that their model outperforms simpler models in terms of predictive performance, and they were able to discover both individual biomarkers and interacting gene pairs (Wu).

Another study on breast cancer from 2016 aimed to identify “gene signatures” that predict chemosensitivity, that is, which tumors react to chemotherapy in breast cancer by combining genetic algorithms with sparse logistic regression. What makes this analysis relevant and important is that it predicts which patients will react to chemotherapy, which gives more personalized treatment. However, there are several genes and possible combinations, like genetic algorithms that aid in searching space, while sparse logistic regression aids in reducing characteristics. The results show that SLR-28 and Notch-86, two gene signatures, perform well on training and validation sets in terms of accuracy, specificity, sensitivity, and other metrics (Hu).

One other useful way logistic regression is applied in the medical field is in identifying how the general public makes decisions regarding their health. Researchers in China analyzed 2696 health survey responses collected from individuals across 31 different Chinese provinces. They analyzed the data with a binary logistic regression model to classify points into two categories: unilateral decision making (value of 1), or collaborative decision making (value of 0); the researchers wanted to identify top predictors of individuals that make medical decisions by themselves and which predictors are correlated with patients making health decisions with more than one party (i.e. a patients, doctor, and family member all helping to make the health decision). It was found that most responses were classified as collaborative decision making (70%), which supports the idea that individuals in China strongly value family- made decisions and strong family values. It was also concluded that

significant predictors of unilateral decision making were gender, education level, family status, religious beliefs and occupation (Liu et al., 2024).

Logistic regression also assists road engineers and traffic control around the world by identifying common predictors of traffic accidents and predictors of severe accidents. According to The World Health Organization, one of the most common unnatural causes of death across the world is road accidents, so it is important to identify strong predictors associated with such accidents (Akter et al., 2021). Researchers in China in 2024 conducted a study that aimed to find which factors in traffic are strongly associated with the occurrence of traffic accidents. They used binary logistic regression to model the probability of a traffic accident occurring given a set of 25 predictors related to road safety (cite the source). Another road traffic safety study from 2021 was conducted in Bangladesh to analyze strong predictors of motorcycle accidents. These researchers also utilized a binary logistic regression model to find strong predictors of severe accidents (Akter) \[say what the results are\]. “Modeling Road Accident Severity with Logistic Regression (comparison study)” is a third study exemplifying the use of a binary logistic regression model to analyze traffic risk. Researchers compared the results of the logistic regression model to results of a decision tree mode and a random forest model, and it was found that the logistic regression model were more clear and understandable than the others. All three of these studies concluded by stating that there are several significant variables found when predicting severe road crashes. Knowing these significant predictors helps builders and developers eliminate or reduce these risk factors as they are building new roads; hence, it is crucial to continue researching road accident severity with logistic regression so that road safety is improved (Akter).

Environmental issues can also be studied using logistic regression analysis due to its interesting properties; after all logistic regression is a generalized linear model, which conducts mapping from any real number to probability values. “Priority prediction of Asian Hornet sighting report using machine learning methods” seeks to address the problem of Asian giant hornets. They are an invasive species that pose a significant threat to native bee populations and local beekeeping, as well as to public safety due to their aggressive nature and potent venom. The goal of the research is to create an automated system to predict the priority of Asian giant hornet sighting reports. The authors modeled the priority prediction of sighting reports as a two-classification problem, with classes being either a "true positive" or a "false positive.” Their methodology is a straightforward application of logistic regression with feature extraction. Researchers then used a weighted binary cross-entropy function and the logistic regression is used for mapping the probability given the feature vector. The model achieved an average prediction accuracy of 83.5% on positive reports with the best weighting parameter settings, but still far from other works which achieved about 93% using Deep Learning. It was concluded that this still needs a lot of improvement or maybe it will never outmatch other methods due to hidden limitations.

One other example of logistic regression used in environmental contexts is in the article “Autoregressive Logistic Regression Applied to Atmospheric Circulation Patterns.” Researchers incorporate autoregressive time dependencies into logistic regression for climate modeling. They work with complex climatological dynamic data, and they explain both interpretation and simulation capabilities for weather patterns (Guanche et al., 2014).

## Method

We chose our topic as logistic regression. So What is logistic regression?

**Mathematically:**

Logistic regression is a statistical modeling technique that predicts the probability of a binary outcome (such as 0 or 1) using one or more independent variables.

## Mathematical Formulation

The key idea is to model the **log odds** (also called the logit) of the probability of the event as a linear function of the predictors:

-   log⁡(p1−p)=β0+β1x1+β2x2+…+βkxklog(1−pp)=β0+β1x1+β2x2+…+βkxk

where pp is the probability of the outcome (e.g., stroke), the xixi are predictors, and the βiβi are their coefficients.​

-   Solving for pp, the equation becomes:

-   p=11+e−(β0+β1x1+…+βkxk)p=1+e−(β0+β1x1+…+βkxk)1

This is the **logistic function**, which always outputs values between 0 and 1, making it ideal for probabilities.​

Here is a picture of Logistic Regression on a predictor variable.

## Logistic Function Example

\![Workflow for Stroke Dataset](LogisticFunctionEg,png)

**Patient data points** (age, glucose, hypertension, heart disease, BMI, smoking status) are plotted and colored by stroke outcome (0 = no stroke, 1 = stroke).

The **logistic regression curve** (S-shaped sigmoid) fits the data and maps predictor values to estimated stroke probability.

A **vertical threshold line** (at probability 0.5) divides the plot, indicating the decision boundary for binary classification.

**Below the curve**: patients more likely classified as "no stroke."

**Above the curve**: patients more likely classified as "stroke."

**(1) Odds** are defined as p/(1−p)p/(1-p)p/(1−p), the ratio of the probability of the event to the probability of its complement.

\(2\) The **logit** transformation (natural log of the odds) turns this nonlinear problem into a linear one, so standard linear modeling techniques can be used for estimation.

\(3\) Coefficients (β) are commonly estimated using **maximum likelihood** methods, not ordinary least squares.

A comparison between Logistic Regression and Multiple Regression is shown below

|  |  |  |
|----|----|----|
| Feature | Multiple Regression | Logistic Regression |
| Outcome variable type | Continuous (real numbers) | Categorical/Binary (e.g., 0 or 1) |
| Example prediction | Predicting house prices | Predicting disease presence/absence |
| Model equation | Linear combination of predictors | Log odds/logit (S-shaped curve: logistic function) |
| Estimation method | Least squares | Maximum likelihood |
| Output type | Actual values (e.g., \$125,000) | Probability of being in a category (e.g., 87%) |
| Usage | Continuous outcome (income, cost, score) | Categorical outcome (yes/no, 0/1) |

We chose a dataset by Fedesoriano in Kaggle to use logistic regression on. The dataset has 5110 observations with 12 variables.

\(1\) Unique ID

\(2\) Gender (Male, Female, Other) – variable type: categorical

\(3\) Age – variable type: continuous

(4)  Hypertension (Hypertension, no Hypertension) -variable type: categorical

(5)  Heart Disease (heart disease, no heart disease) – variable type: categorical

\(6\) Marital Status (married, or not married) – variable type: categorical

\(7\) Work Type (private, self-employed, other, public service, children) – variable type: categorical

(8)  Residence Type (urban, rural) – variable type: categorical

\(9\) Average Glucose Level (In the blood) – variable type - continuous

\(10\) BMI (Body Mass Index) -variable type - continuous

\(11\) Smoking Status (smokes, formerly smokes, never smoked, unknown) – variable type: categorical

\(12\) Stroke (Stroke or no Stroke) variable type: categorical (the outcome variable)

**Since the outcome variable stroke 2 outcomes (stroke or no stroke), the choice is confirmed to be logistic regression as the model to be used on this dataset.**

 We then uploaded the Kaggle dataset into R studio server and analyzed it with R. We first utilized 12 different packages and libraries. They are listed below. These packages and libraries gave us the statistical models we then used to analyze the Kaggle dataset.

1\. dplyr

2\. car

3\. ResourceSelection

4\. caret

5\. pROC

6\. logistf

7\. Hmisc

8\. rcompanion

9\. ggplot2

10. knitr
11. summarytools
12. DescTools

We first prepared the data, ensuring that all variables in the dataset, both predictor and outcome variables were converted or recoded to numeric as follows:

\(1\) age (continuous), we decided to recode to numeric with 2 places after the decimal.

\(2\) gender (categorical) we coded 1 for male and 2 for female. There was only 1 case where it was coded other. We recoded other as N/A. We coded this as categorical.

\(3\) hypertension had 2 categories and was coded as categorical

\(4\) heart disease had 2 categories and was coded as categorical

\(5\) marital status had 2 categories, married, or not married and was coded as categorical

\(6\) Work type had 4 categories1 = Government, 2 = private sector, 3 = self-employed, 4 = never worked and was coded as categorical

\(7\) residence type had 2 categories rural and urban and was coded as categorical

\(8\) bmi (continuous) was recoded as numeric with 2 places after the decimal

\(9\) average glucose level(continuous) was recoded as numeric with 2 places after the decimal

\(10\) smoking status had 4 categories, smoking, nonsmoking, previous smoking, and other. It was coded as categorical.

\(11\) ID number -was left as is and deleted because it’s not needed

 (12) Stroke (outcome is categorical has 2 categories, 1 = stroke, 0 = no stroke

 Once that was done, we got rid of extraneous values such as “N/A”. After deleting rows that were useless or irrelevant values were left with a dataset of 3357 cases, 11 predictor variables and an outcome variable. As the rule of thumb for minimal size to run analyses is 15 cases per number of predictor variables.  Applying this rule of thumb to our project, the dataset’s minimum is 132 cases. Since the cleaned dataset has 3357 cases, we can use logistic regression on the dataset.

Once the variables were coded correctly, we then confirmed it and ran a histogram to confirm the values for each categorical variable and reviewed the frequency distribution for the numerical variables.

In addition, we ran the mean, range, and standard deviation for numerical variables.

We then turned to the use of logistic regression on the dataset. For logistic regression to be used on the dataset, it had to pass 6 assumptions

[(1) Assumption 1: The outcome variable was binary.  In this case 0 or 1.]{.underline}

We can confirm this from the histogram of the outcome variable (stroke or no stroke)

[(2) Assumption 2: There is a linear relationship between i.e., Logit (log- of the odds ratio) of the outcome and each continuous linear predictor is linear]{.underline}

Mathematically logit (p) = Log ).

We Test for this with the Box-Tidwell test to check for linearity between the predictors and the logit. The procedure adds the log transformed interaction terms between the continuous independent variables. The interaction terms is then added as a new variable, so for example Age becomes ln (Age).

Note: For the Box Tidwell test we will filter the dataset to keep continuous independent predictors. We then add the interaction terms and re-run the logistic regression. We then check the interaction terms and look for the P values. If there are not statistically significant P values I.e., P ≥ .05 then the variables are linearly related to the logit outcome variable and the assumption is satisfied.

[(3) Assumption 3: No influential outliers. Influential outliers distort the accuracy and outcome of the model]{.underline}.

We can check for this with Cooks D (Cooks Distance) to determine the influence of a data point. Cooks D is calculated based on its residual and leverage. It summarizes the changes in the regression model when that particular (ith) observation s removed. As a popular method the threshold is 4/N where N is the number of observations. If Cooks distance is \> 4/N rt hen we have influential outliers. We can also plot Cooks D. Data points with standardized residual values greater than 5 represent possible extreme outliers.

([4) Assumption 4: No multicollinearity]{.underline}. Multicollinearity is where the data set contains strongly correlated independent variables. This becomes a problem because it reduces the statistical power of the logistic regression model. We can check this with VIF (Variance Inflation Factor).

Mathematically:  VIF = the ratio of the overall Model variance to the variance of a model that includes only that single independent variable. The smallest possible value for VIF = 1 (a complete absence of multicollinearity).  A rule of thumb says a VIF values that exceeds 5 or 10 indicates a problem with multicollinearity.

[(5) Assumption 5: Independence of Observations.]{.underline} Each observation is independent of each other. Ie they are not repeated or paired data. Based on the definition of the Kaggle dataset, each observation of the Kaggle dataset is a different patient. So, this assumption is met.

[(6) Assumption 6: The dataset N size.]{.underline} If we have small N size, it affects Logistic Regression in several ways:

(a) Bias in the Parameter Estimates:

1.the Maximum Likelihood Estimate (MLE) used for Logistic Regression can produce biased estimates. Especially If the events are rare.

2.  Odds ratios tend to be overestimated and standard errors for coefficients become large and unreliable.

b\. Separation Problems: With very small samples, we may have complete or quasi- complete separation. The optimizer cannot estimate finite parameters and the standard logistic regression will fail to converge. 

c.  Statistical Power:  A small N size means low statistical power, in other words. Unable to detect true associations. Especially for less frequent predictors or outcomes.      

We can test for this with a rule of thumb:  There needs to be at least 10 cases for every predictor and a minimal total of 500 cases. Since we have 12 predictors the minimum number of cases is 12 x 10 = 120 cases.

Once we determine that the assumptions are met, we plan to look at 3 different logistical regression models, the base logistic regression, a firth logistic regression model and a refinement of the firth logistic regression model called FLIC.

[Developing 3 Different Logistic Regression Models]{.underline}

We decided to develop 3 different logistic regression models. The rationale for this came from the percentage of strokes from the Kaggle dataset compared to the percentage of strokes in the US. The Percentage of strokes in the Kagle dataset is 5.6%, Compared the CDC’s percentage of strokes at 3.1%.  There are problems with bias, separation and skewed predicted probabilities.

\(1\) Small Sample Bias is an issue where the outcome is a stroke, is rare, which could produce biased parameter estimates. So, there is a danger of over or under estimation of stroke risk, because the datasets prevalence rate differs from population in the US.

\(2\) Separation: if the dataset is imbalanced there is a danger of categories of predictors predicting the outcome at perfect percentage of 100% or near perfect. The Coefficient estimates cam become infinite or very large making the basic logistic regression model unreliable.

(3)  miscallibrated probabilities: The predicted probabilities from standard logistic regression can be skewed when the datasets outcome of a stroke, 5.6% doesn’t match the population levels.

Because of these reasons, 2 alternative models are being used to compare. Firth Regression and Refinement of Firth Regression called FLIC.

In datasets of rare events, Firth Regression introduces bias reduction thru Jeffries Prior that reduces the biases in datasets with rare events.  This pulls parameter estimates away from infinity and large numbers.

Firth regression produced refined finite estimates even if there is perfect prediction between predictors that perfectly separate stroke vs no stroke cases.

Finally, Firth Regression produces results like large sample size.

probability calibration: Firth regression, while correcting bias, tends to bias predicted event probabilities (average predicted   toward 0.5. Your stroke model could predict higher risk for all, regardless of the actual prevalence.

FLIC (Firth’s logistic regression with intercept correction) adjusts the intercept after fitting the model so that the average predicted probability exactly matches the observed rate in your data (5.6% in this case). This is especially useful if your sample prevalence intentionally differs from the “true” population prevalence, as in case-control studies or enriched samples.

[Analyzing the 3 models]{.underline}

The Three different Models of Logistic Regression: Baseline Firth and Flic Correction. We are creating 3 different models to really test to see if the dataset had a stroke percentage that is less than the real percentage of stroke to population ratio in the US. Because this is a so called “rare event” Firth regression takes this into account. as does its refinement FLIC.

We will then compare  the models performance by  using a confusion matrix, area under curve (AUC) and Youden’s J

A confusion matrix is a tool used to evaluate the performance of a classification model (in this case a logistic regression model classifying the outcome as stroke or no stroke. It’s way of comparing true and false positives and true and false negatives. This is very similar to a type1/type 2 error table in regression analysis. The difference being in that the type1/type 2 error table looks at the probability of error to predict to the population whereas the confusion matrix looks at model categorization.

**A Typical Confusion Matrix**

[A Confusion Mat](confusionmatrix.png)

A Confusion Matrix rix creates several measures of a categorical model’s performance.

[The ran](accuracy.png)[ge of Youd](ConfusionMeasures.png)

Youden’s J ranges from 0 (No diagnostic ability) to 1 (Perfect Diagnostic Ability). In other words, a 0 means the model performance no better than chance, while a 1 means the model has perfect sensitivity and specificity. It’s used to see the optimal threshold for a model.

Graphically The point on the ROC curve where J is maximized is farthest from its diagonal and represents the best trade off between specificity and sensitivity.

Youden’s J is valuable as a single performance metric that gives equal weight to false positives and false negatives. This makes it useful in medical diagnostics where balanced accuracy is crucial.

**Results and Analyses**

```{r}
options(repos = c(CRAN = "https://cloud.r-project.org"))

```

```{r}
#| echo: false
#| message: false
#| warning: false
pkgs <- c("dplyr", "car", "ResourceSelection", "caret", "pROC",  "logistf", "Hmisc", "rcompanion", "ggplot2", "summarytools", "knitr", "gt", "DescTools")
invisible(
  lapply(pkgs, function(pkg) suppressMessages(suppressWarnings(library(pkg, character.only = TRUE))))
)
```

Coding the Predictors and Omitting irrelevant values

Because we are using Logistic Regression a Quantitative tool, all predictors and the outcome variable must also be coded to quantitative equivalents. We also had to deal with N/A...so there were predictor variables in the dataset that had "N/A", Unknown, Children and Other. It would be easier to recode all the irrelevant values as "N/A" and get rid of them all at the same time. We also recoded gender to 1 as male and 2 as female. We also limited the bmi predictor to 2 places after the decimal.Finally we recoded all text categorical variables into numeric variables.

```{r}
#| echo: false
stroke1 <- read.csv("stroke.csv")
stroke1[stroke1 == "N/A" | stroke1 == "Unknown" | stroke1 == "children" | stroke1 == "other"] <- NA
stroke1$bmi <- round(as.numeric(stroke1$bmi), 2)
stroke1$gender[stroke1$gender == "Male"] <- 1
stroke1$gender[stroke1$gender == "Female"] <- 2
stroke1$gender <- as.numeric(stroke1$gender)
stroke1$ever_married[stroke1$ever_married == "Yes"] <- 1
stroke1$ever_married[stroke1$ever_married == "No"] <- 2
stroke1$ever_married <- as.numeric(stroke1$ever_married)
stroke1$work_type[stroke1$work_type == "Govt_job"] <- 1
stroke1$work_type[stroke1$work_type == "Private"] <- 2
stroke1$work_type[stroke1$work_type == "Self-employed"] <- 3
stroke1$work_type[stroke1$work_type == "Never_worked"] <- 4
stroke1$work_type <- as.numeric(stroke1$work_type)
stroke1$Residence_type[stroke1$Residence_type == "Urban"] <- 1
stroke1$Residence_type[stroke1$Residence_type == "Rural"] <- 2
stroke1$Residence_type <- as.numeric(stroke1$Residence_type)
stroke1$avg_glucose_level <- as.numeric(stroke1$avg_glucose_level)
stroke1$heart_disease <- as.numeric(stroke1$heart_disease)
stroke1$hypertension <- as.numeric(stroke1$hypertension)
stroke1$age <- round(as.numeric(stroke1$age), 2)
stroke1$stroke <- as.numeric(stroke1$stroke)
stroke1$smoking_status[stroke1$smoking_status == "never smoked"] <- 1
stroke1$smoking_status[stroke1$smoking_status == "formerly smoked"] <- 2
stroke1$smoking_status[stroke1$smoking_status == "smokes"] <- 3
stroke1$smoking_status <- as.numeric(stroke1$smoking_status)
stroke1 <- stroke1[, !(names(stroke1) %in% "id")]


```

```{r}
stroke1$stroke <- as.factor(stroke1$stroke)
stroke1_clean <- na.omit(stroke1)
strokeclean <- stroke1_clean
fourassume <- stroke1_clean
```

Showing Descriptive Statistics for all variables, Mean, Std Deviation, and Interquartile Range

```{r}
#| echo: false
 descriptivestats <- strokeclean %>%
  summarise(
    Mean_Age = mean(age, na.rm = TRUE),
    Range_Age = paste(range(age, na.rm = TRUE), collapse = " - "),
    SD_Age = sd(age, na.rm = TRUE),
    Mean_BMI = mean(bmi, na.rm = TRUE),
    Range_BMI = paste(range(bmi, na.rm = TRUE), collapse = " - "),
    SD_BMI = sd(bmi, na.rm = TRUE), # Use lowercase 'bmi' for consistency
    Mean_AvgGlucoseLvl = mean(avg_glucose_level, na.rm = TRUE),
    Range_AvgGlucoseLvl = paste(range(avg_glucose_level, na.rm = TRUE), collapse = " - "),
    SD_AvgGlucoseLvl = sd(avg_glucose_level, na.rm = TRUE)
  )
kable(descriptivestats, caption = "Descriptive Statistics")
```

Looking at the distribution of all the predictor indicators and the outcome indicator with Histograms

```{r}
ggplot(strokeclean, aes(x = gender)) +
  geom_bar(fill = "blue") +
  geom_text(
    stat = "count",
    aes(label = after_stat(count)),
    vjust = -0.25,
    size = 5
  ) +
  labs(title = "Histogram of gender", x = "gender", y = "count")
  
  labs(title = "Histogram of gender", 
       x = "gender", 
       y = "Frequency")
ggplot(strokeclean, aes(x = age)) +
  geom_histogram(
                 fill = "green", 
                 color = "white") +
  labs(title = "Histogram of Age", 
       x = "Age", 
       y = "Frequency")

ggplot(strokeclean, aes(x = hypertension)) +
  geom_bar(fill = "purple") +
    geom_text(
    stat = "count",
    aes(label = after_stat(count)),
    vjust = -0.25,
    size = 5
    ) +  
  labs(title = "Histogram of hypertension", 
       x = "hypertension", 
       y = "Frequency")

ggplot(strokeclean, aes(x = heart_disease)) +
  geom_bar(fill = "orange") +
    geom_text(
    stat = "count",
    aes(label = after_stat(count)),
    vjust = -0.25,
    size = 5
    ) +  
  labs(title = "Histogram of heart_disease", 
       x = "HeartDisease", 
       y = "Frequency")

ggplot(strokeclean, aes(x = ever_married)) +
  geom_bar(fill = "aquamarine") +
    geom_text(
    stat = "count",
    aes(label = after_stat(count)),
    vjust = -0.25,
    size = 5
    ) +  
  labs(title = "Histogram of ever_married", 
       x = "EverMarried", 
       y = "Frequency")

ggplot(strokeclean, aes(x = work_type)) +
  geom_bar(fill = "steelblue") +
    geom_text(
    stat = "count",
    aes(label = after_stat(count)),
    vjust = -0.25,
    size = 5
    ) +  
  labs(title = "Histogram of work_type", 
       x = "WorkType", 
       y = "Frequency")

ggplot(strokeclean, aes(x = Residence_type)) +
  geom_bar(fill = "magenta") +
    geom_text(
    stat = "count",
    aes(label = after_stat(count)),
    vjust = -0.25,
    size = 5
    ) +  
  labs(title = "Histogram of Residence_type", 
       x = "Residence_type", 
       y = "Frequency")

ggplot(strokeclean, aes(x = avg_glucose_level)) +
  geom_histogram(binwidth = 10, fill = "green",
                                color = "white") +
  labs(title = "Histogram of avg_glucose_level",
       x = "avg_glucose_level",
       y = "Frequency")

ggplot(strokeclean, aes(x = bmi)) +
  geom_histogram(binwidth = 2, fill = "gold", color = "black") +
  labs(title = "Histogram of BMI", x = "BMI", y = "Frequency") +
  theme_minimal()

  
ggplot(strokeclean, aes(x = smoking_status)) +
  geom_bar(fill = "deepskyblue") +
    geom_text(
    stat = "count",
    aes(label = after_stat(count)),
    vjust = -0.25,
    size = 5
    ) +  
  labs(title = "smoking_status", 
       x = "smoking_status", 
       y = "Frequency")

ggplot(strokeclean, aes(x = stroke)) +
  geom_bar(fill = "tan") +
    geom_text(
    stat = "count",
    aes(label = after_stat(count)),
    vjust = -0.25,
    size = 5
    ) +  
  labs(title = "Histogram of Age", 
       x = "stroke", 
       y = "Frequency")

```

### The Basic Logistic Regression Model

```{r}
formula <- stroke ~ gender + age + hypertension + heart_disease + ever_married +
  work_type + Residence_type + avg_glucose_level + bmi + smoking_status
```

```{r}
#| echo: false
# Assumption 1: The Outcome Variable is 0 or 1
unique(fourassume$stroke)
# Assumption 2: There is linear relationship between the outcome variable and each predictor that is numeric. Categorical predictors are reviewed in the histograms avove
fourassume$ageadj <- fourassume$age + abs(min(fourassume$age)) + 1
fourassume$avg_glucose_leveladj <- fourassume$avg_glucose_level + abs(min(fourassume$avg_glucose_level)) + 1
fourassume$bmiadj <- fourassume$bmi + abs(min(fourassume$bmi)) + 1
str(fourassume)
numeric_vars <- sapply(fourassume, is.numeric)
fourassume_numeric <- fourassume[, numeric_vars]
corr_results <- rcorr(as.matrix(fourassume_numeric))
fourAdj <- fourassume
fourAdj <- fourAdj[ , !(names(fourAdj) %in% c("age", "heart_disease", "avg_glucose_level", "bmi")) ]
model4 <- glm(stroke ~ ageadj + avg_glucose_leveladj + bmiadj, data=fourAdj, family=binomial)
residualPlots(model4)
# Assumption 3: Assess Influentional Outliers that are numeric. Categorical predictors are reviewed n the hhistrams above
alias(model4)
influencePlot(model4)
# Assumption 4: Assess Multicollinearity for numeric predictors
vif_values <- vif(model4)
max_vif <- max(vif_values)
infl <-influencePlot(model4, id = FALSE)
cooks_d <- infl$statistics[, "cookD"]
n_influential <-sum(cooks_d > 0.5)
results_table <- data.frame(
  Check = c(
    "Max VIF (multicollinearity)",
    "InfluentialCases (cooks_d > 0.5"
  ),
  Value = c(
    round(max_vif, 2),
    n_influential
  )
)
kable(results_table, caption = "key Regression Diagnostics")

# Predictive Capability
model4_CM <- glm(stroke ~ gender + age + hypertension + heart_disease + ever_married + work_type + Residence_type + avg_glucose_level + bmi + smoking_status, data=fourassume, family = binomial)
```

```{r}
#| echo: false
# Baseline Logistic Regression
model_base <- glm(formula, data=strokeclean, family=binomial)
prob_base <- predict(model_base, type="response")

# Firth Logistic Regression
model_firth <- logistf(formula, data=strokeclean)
prob_firth <- predict(model_firth, type="response")

# FLIC Correction (this correction changes the intercept)
model_flic <- flic(formula, data=strokeclean)
prob_flic <- predict(model_flic, type="response")

labels <- strokeclean$stroke

```

```{r}
#| echo: false
youden_point <- function(roc_obj) {
  coords <- coords(roc_obj, "best", best.method = "youden", ret=c("threshold", "sensitivity", "specificity", "youden"))
  return(coords)
}
```

```{r}
# Predictions with default threshold 0.5 (for output consistency)
pred_base <- factor(ifelse(prob_base > 0.5, 1, 0), levels=c(0,1))
pred_firth <- factor(ifelse(prob_firth > 0.5, 1, 0), levels=c(0,1))
pred_flic <- factor(ifelse(prob_flic > 0.5, 1, 0), levels=c(0,1))
```

```{r}
#| echo: false
  pred_base <- factor(ifelse(prob_base > 0.5, 1, 0), levels=c(0,1))
  pred_firth <- factor(ifelse(prob_firth > 0.5, 1, 0), levels=c(0,1))
  pred_flic <- factor(ifelse(prob_flic > 0.5, 1, 0), levels=c(0,1))

  metrics <- function(pred, prob, labels, name) {
    cm <- confusionMatrix(pred, labels, positive = "1")
    roc_obj <- suppressMessages(roc(labels, as.numeric(prob)))
    auc_val <- suppressMessages(auc(roc_obj))
    precision <- suppressMessages(cm$byClass["Pos Pred Value"])
    recall <- suppressMessages(cm$byClass["Sensitivity"])
    f1 <- 2 * ((precision * recall) / (precision + recall))
    youden <- youden_point(roc_obj)
    # All list arguments separated by commas only, no '+'
    list(
      confusion = cm$table,
      precision = precision,
      recall = recall,
      f1 = f1,
      auc = auc_val,
      roc_obj = roc_obj,
      youden = youden,
      model = name
    )
  }

```

Intialize Results. We have to initialize results before calling the model

```{r}
#| echo: false
results_base <- metrics(pred_base, prob_base, labels, "Baseline LR")
results_firth <- metrics(pred_firth, prob_firth, labels, "firth LR")
results_flic <- metrics(pred_flic, prob_flic, labels, "flic LR")

df_base <- data.frame(Model = results_base$model,
                      Precision = results_base$precision,
                      Recall = results_base$recall,
                      F1 = results_base$f1,
                      AUC = as.numeric(results_base$auc),
                      Youden = results_base$youden)
df_firth <- data.frame(Model = results_firth$model,
                       Precision = results_firth$precision,
                       Recall = results_firth$recall,
                       F1 = results_firth$f1,
                       AUC = as.numeric(results_firth$auc),
                       Youden = results_firth$youden)
df_flic <- data.frame(Model = results_flic$model,
                      Precision = results_flic$precision,
                      Recall = results_flic$recall,
                      F1 = results_flic$f1,
                      AUC = as.numeric(results_flic$auc),
                      Youden = results_flic$youden)
all_metrics <- bind_rows(df_base, df_firth, df_flic)
kable(all_metrics, digis = 3, caption = "Logistic Regression Model Metrics Comparison")



```

```{r}
plot(results_base$roc_obj, col="cyan", main="ROC Curves: Baseline (blue) vs Firth (red)")
plot(results_firth$roc_obj, col="magenta", add=TRUE)
plot(results_flic$roc_obj, col ="gold", add=TRUE)
auc(results_base$roc_obj)
auc(results_firth$roc_obj)
auc(results_flic$roc_obj)

points(
  1-results_base$youden["specificity"],
  results_base$youden["sensitivity"],
  col="cyan", pch=19, cex=1.5
)
points(
  1-results_firth$youden["specificity"],
  results_firth$youden["sensitivity"],
  col="magenta", pch=19, cex=1.5
)
points(
  1-results_flic$youden["specificity"],
  results_flic$youden["sensitivity"],
  col="gold", pch=19, cex=1.5
)

legend("bottomright", legend=c("Baseline", "Firth","flic"), col=c("cyan", "magenta", "gold"), lwd=2)

text(
  x=1-results_base$youden["specificity"], y=results_base$youden["sensitivity"],
  labels=paste0("Youden: ", round(results_base$youden["youden"], 3)),
  pos=4, col="cyan"
)
text(
  x=1-results_firth$youden["specificity"], y=results_firth$youden["sensitivity"],
  labels=paste0("Youden: ", round(results_firth$youden["youden"], 3)),
  pos=4, col="magenta"
)
text(
  x=1-results_flic$youden["specificity"], y=results_flic$youden["sensitivity"],
  labels=paste0("Youden: ", round(results_flic$youden["youden"], 3)),
  pos=4, col="gold"
)
```

Here we see the results. Note that overlaying the curves and Youden's J is EXACTLY the same for all three models. This is a strong indication that the dataset is currently balanced enough to distinguish between stroke and non stroke. The bias if any would have shown up in a different AUC curve, and a different Youden's J. It does not.

Plot the Confusion Matrices

```{r}
par(mfrow = c(3, 1), mar = c(6, 5, 6, 2))  # more top margin for all
fourfoldplot(results_base$confusion, color = c("lightskyblue", "gold"),
             conf.level = 0, margin = 1, main = "Baseline Confusion Matrix")
fourfoldplot(results_firth$confusion, color = c("lightskyblue", "chartreuse"),
             conf.level = 0, margin = 1, main = "Firth Confusion Matrix")
fourfoldplot(results_flic$confusion, color = c("cyan", "plum2"),
             conf.level = 0, margin = 1, main = "Flic Confusion Matrix")
par(mfrow = c(1,1), mar = c(5, 4, 4, 2)) # Reset to default after

```

The results indicate exactly that the confusion matrices are exactly the same. So the conclusion we can reach is the there was no significant bias in the dataset. The dataset can distinguish between stroke and non stroke events with sufficient selectivity.

**Future Directions and Conclusion**

There are two areas that the resulting analysis showed. (1) Methodological and (2) Changes to the procedure.

\(1\) Methodological Issues:
